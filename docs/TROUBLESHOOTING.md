# ğŸ”§ æ•…éšœæ’é™¤å®Œæ•´æŒ‡å—

æœ¬æ–‡æ¡£åˆ—å‡ºäº† Qwen3-0.6B æ ‘è“æ´¾éƒ¨ç½²è¿‡ç¨‹ä¸­å¯èƒ½é‡åˆ°çš„æ‰€æœ‰é—®é¢˜åŠå…¶è§£å†³æ–¹æ¡ˆã€‚

---

## ğŸ“‹ ç›®å½•

1. [è®­ç»ƒé˜¶æ®µé—®é¢˜](#1-è®­ç»ƒé˜¶æ®µé—®é¢˜)
2. [æ¨¡å‹è½¬æ¢é—®é¢˜](#2-æ¨¡å‹è½¬æ¢é—®é¢˜)
3. [ä¼ è¾“é—®é¢˜](#3-ä¼ è¾“é—®é¢˜)
4. [ç¼–è¯‘é—®é¢˜](#4-ç¼–è¯‘é—®é¢˜)
5. [è¿è¡Œæ—¶é—®é¢˜](#5-è¿è¡Œæ—¶é—®é¢˜)
6. [æ€§èƒ½é—®é¢˜](#6-æ€§èƒ½é—®é¢˜)
7. [ç½‘ç»œé—®é¢˜](#7-ç½‘ç»œé—®é¢˜)
8. [ç³»ç»Ÿé—®é¢˜](#8-ç³»ç»Ÿé—®é¢˜)

---

## 1. è®­ç»ƒé˜¶æ®µé—®é¢˜

### âŒ é—®é¢˜: CUDA Out of Memory (OOM)

**ç—‡çŠ¶**:
```
RuntimeError: CUDA out of memory. Tried to allocate X.XX MiB
```

**åŸå› **:
- GPU å†…å­˜ä¸è¶³
- Batch size å¤ªå¤§
- æ¨¡å‹åŠ è½½å ç”¨è¿‡å¤šå†…å­˜

**è§£å†³æ–¹æ¡ˆ**:

```python
# æ–¹æ¡ˆ 1: å‡å° batch size
PER_DEVICE_TRAIN_BATCH_SIZE = 2  # ä» 4 æ”¹ä¸º 2
GRADIENT_ACCUMULATION_STEPS = 8  # ä» 4 æ”¹ä¸º 8

# æ–¹æ¡ˆ 2: å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
USE_GRADIENT_CHECKPOINTING = True

# æ–¹æ¡ˆ 3: ä½¿ç”¨æ›´æ¿€è¿›çš„é‡åŒ–
LOAD_IN_4BIT = True  # å¯ç”¨ 4-bit é‡åŒ–

# æ–¹æ¡ˆ 4: å‡å°åºåˆ—é•¿åº¦
MAX_SEQ_LENGTH = 1024  # ä» 2048 æ”¹ä¸º 1024
```

### âŒ é—®é¢˜: Unsloth å®‰è£…å¤±è´¥

**ç—‡çŠ¶**:
```
ERROR: Failed building wheel for unsloth
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# æ–¹æ¡ˆ 1: ä½¿ç”¨é¢„ç¼–è¯‘ç‰ˆæœ¬
pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"

# æ–¹æ¡ˆ 2: æ£€æŸ¥ CUDA ç‰ˆæœ¬
nvidia-smi
# ç„¶åå®‰è£…å¯¹åº”çš„ PyTorch ç‰ˆæœ¬
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# æ–¹æ¡ˆ 3: ä½¿ç”¨ conda
conda create -n unsloth python=3.10
conda activate unsloth
conda install pytorch pytorch-cuda=11.8 -c pytorch -c nvidia
pip install unsloth
```

### âŒ é—®é¢˜: æ•°æ®åŠ è½½å¤ªæ…¢

**ç—‡çŠ¶**:
- è®­ç»ƒå¼€å§‹å‰ç­‰å¾…å¾ˆä¹…
- æ•°æ®é¢„å¤„ç†å ç”¨å¤§é‡æ—¶é—´

**è§£å†³æ–¹æ¡ˆ**:

```python
# ä½¿ç”¨æµå¼åŠ è½½
dataset = load_dataset(
    DATASET_NAME,
    split=DATASET_SPLIT,
    streaming=True  # å…³é”®ï¼
)

# å‡å°‘é‡‡æ ·æ•°é‡
NUM_SAMPLES = 50000  # ä» 100000 é™ä½

# ä½¿ç”¨ç¼“å­˜
dataset = dataset.cache()
```

---

## 2. æ¨¡å‹è½¬æ¢é—®é¢˜

### âŒ é—®é¢˜: GGUF è½¬æ¢å¤±è´¥

**ç—‡çŠ¶**:
```
AttributeError: 'FastLanguageModel' object has no attribute 'save_pretrained_gguf'
```

**åŸå› **:
- Unsloth ç‰ˆæœ¬è¿‡æ—§
- llama.cpp ä¸å…¼å®¹

**è§£å†³æ–¹æ¡ˆ**:

```bash
# æ›´æ–° Unsloth
pip install --upgrade unsloth

# æ‰‹åŠ¨ä½¿ç”¨ llama.cpp è½¬æ¢
cd ~/llama.cpp

# 1. è½¬æ¢ä¸º FP16 GGUF
python convert.py /path/to/pytorch/model --outfile model-f16.gguf

# 2. é‡åŒ–
./quantize model-f16.gguf model-q4_k_m.gguf Q4_K_M
```

### âŒ é—®é¢˜: é‡åŒ–åè´¨é‡ä¸‹é™ä¸¥é‡

**ç—‡çŠ¶**:
- æ¨¡å‹è¾“å‡ºä¸è¿è´¯
- é‡å¤å†…å®¹è¿‡å¤š
- å›ç­”è´¨é‡æ˜æ˜¾ä¸‹é™

**è§£å†³æ–¹æ¡ˆ**:

```bash
# ä½¿ç”¨æ›´é«˜ç²¾åº¦çš„é‡åŒ–
./quantize model-f16.gguf model-q8_0.gguf Q8_0  # ä» Q4 å‡åˆ° Q8

# æˆ–ä½¿ç”¨æ··åˆé‡åŒ–
./quantize model-f16.gguf model-q5_k_m.gguf Q5_K_M
```

---

## 3. ä¼ è¾“é—®é¢˜

### âŒ é—®é¢˜: SCP ä¼ è¾“é€Ÿåº¦æ…¢

**ç—‡çŠ¶**:
- ä¼ è¾“ 400MB éœ€è¦ 30+ åˆ†é’Ÿ
- è¿æ¥ä¸ç¨³å®š

**è§£å†³æ–¹æ¡ˆ**:

```bash
# æ–¹æ¡ˆ 1: ä½¿ç”¨å‹ç¼©ä¼ è¾“
tar -czf model.tar.gz *.gguf
scp -C model.tar.gz pi@raspberrypi.local:~/  # -C å¯ç”¨å‹ç¼©

# æ–¹æ¡ˆ 2: ä½¿ç”¨ rsyncï¼ˆæ›´å¿«ï¼Œå¯æ–­ç‚¹ç»­ä¼ ï¼‰
rsync -avz --progress model.gguf pi@raspberrypi.local:~/models/

# æ–¹æ¡ˆ 3: é™é€Ÿä½†ç¨³å®š
scp -l 8000 model.gguf pi@raspberrypi.local:~/  # é™é€Ÿ 1MB/s
```

### âŒ é—®é¢˜: SSH è¿æ¥è¢«æ‹’ç»

**ç—‡çŠ¶**:
```
ssh: connect to host raspberrypi.local port 22: Connection refused
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. æ£€æŸ¥ SSH æœåŠ¡
sudo systemctl status ssh
sudo systemctl start ssh
sudo systemctl enable ssh

# 2. æ£€æŸ¥é˜²ç«å¢™
sudo ufw allow 22

# 3. ä½¿ç”¨ IP åœ°å€è€Œéä¸»æœºå
ssh pi@192.168.1.xxx

# 4. æŸ¥æ‰¾æ ‘è“æ´¾ IP
# åœ¨æ ‘è“æ´¾ä¸Šæ‰§è¡Œ:
hostname -I

# æˆ–åœ¨è·¯ç”±å™¨ç®¡ç†ç•Œé¢æŸ¥çœ‹
```

---

## 4. ç¼–è¯‘é—®é¢˜

### âŒ é—®é¢˜: llama.cpp ç¼–è¯‘å¤±è´¥

**ç—‡çŠ¶**:
```
make: *** [main] Error 1
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. æ›´æ–°ç¼–è¯‘å·¥å…·
sudo apt update
sudo apt install -y build-essential cmake git

# 2. æ¸…ç†åé‡æ–°ç¼–è¯‘
make clean
make -j4

# 3. å¦‚æœä»ç„¶å¤±è´¥ï¼Œé€ä¸ªç¼–è¯‘
make main
make server

# 4. æ£€æŸ¥ä¾èµ–
gcc --version  # åº”è¯¥ >= 7.0
cmake --version  # åº”è¯¥ >= 3.12
```

### âŒ é—®é¢˜: ç¼ºå°‘ä¾èµ–åº“

**ç—‡çŠ¶**:
```
fatal error: curl/curl.h: No such file or directory
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# å®‰è£…ç¼ºå¤±çš„å¼€å‘åº“
sudo apt install -y \
    libcurl4-openssl-dev \
    libssl-dev \
    pkg-config
```

---

## 5. è¿è¡Œæ—¶é—®é¢˜

### âŒ é—®é¢˜: å†…å­˜ä¸è¶³ï¼ˆOOMï¼‰

**ç—‡çŠ¶**:
```
Killed
```
æˆ–
```
Cannot allocate memory
```

**è¯Šæ–­**:
```bash
# æ£€æŸ¥å†…å­˜ä½¿ç”¨
free -h
# æ£€æŸ¥ OOM killer æ—¥å¿—
dmesg | grep -i "out of memory"
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# æ–¹æ¡ˆ 1: å¢åŠ  swap
sudo dphys-swapfile swapoff
sudo sed -i 's/CONF_SWAPSIZE=.*/CONF_SWAPSIZE=4096/' /etc/dphys-swapfile
sudo dphys-swapfile setup
sudo dphys-swapfile swapon

# æ–¹æ¡ˆ 2: ä½¿ç”¨æ›´å°çš„æ¨¡å‹
# ä½¿ç”¨ Q2_K è€Œé Q4_K_M

# æ–¹æ¡ˆ 3: å‡å°ä¸Šä¸‹æ–‡é•¿åº¦
./main -m model.gguf -c 1024  # ä» 2048 é™åˆ° 1024

# æ–¹æ¡ˆ 4: å‡å°‘çº¿ç¨‹æ•°
./main -m model.gguf -t 2  # ä» 4 é™åˆ° 2

# æ–¹æ¡ˆ 5: å…³é—­æ¡Œé¢ç¯å¢ƒï¼ˆä»…ä¿ç•™ SSHï¼‰
sudo systemctl set-default multi-user.target
sudo reboot
```

### âŒ é—®é¢˜: æ¨¡å‹åŠ è½½å¤±è´¥

**ç—‡çŠ¶**:
```
error loading model: unexpected tensor dtype
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§
sha256sum model.gguf
ls -lh model.gguf  # æ£€æŸ¥å¤§å°æ˜¯å¦æ­£å¸¸

# 2. é‡æ–°ä¸‹è½½/ä¼ è¾“æ¨¡å‹

# 3. æ£€æŸ¥ llama.cpp ç‰ˆæœ¬
cd ~/llama.cpp
git pull
make clean && make -j4

# 4. ä½¿ç”¨ file å‘½ä»¤æ£€æŸ¥æ¨¡å‹
file model.gguf
```

### âŒ é—®é¢˜: æœåŠ¡å¯åŠ¨åæ— å“åº”

**ç—‡çŠ¶**:
- `systemctl status llama-server` æ˜¾ç¤º active
- ä½†æ— æ³•è¿æ¥åˆ°ç«¯å£

**è¯Šæ–­**:

```bash
# æ£€æŸ¥è¿›ç¨‹
ps aux | grep server

# æ£€æŸ¥ç«¯å£
netstat -tuln | grep 8080
# æˆ–
ss -tuln | grep 8080

# æ£€æŸ¥æ—¥å¿—
sudo journalctl -u llama-server -n 50
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. æ£€æŸ¥é˜²ç«å¢™
sudo ufw status
sudo ufw allow 8080

# 2. æ‰‹åŠ¨å¯åŠ¨è°ƒè¯•
cd ~/llama.cpp
./server -m ~/models/qwen3-0.6b-q4_k_m.gguf \
    --host 0.0.0.0 \
    --port 8080 \
    --verbose  # æŸ¥çœ‹è¯¦ç»†æ—¥å¿—

# 3. æ£€æŸ¥æ˜¯å¦ç«¯å£è¢«å ç”¨
lsof -i :8080
```

---

## 6. æ€§èƒ½é—®é¢˜

### âŒ é—®é¢˜: æ¨ç†é€Ÿåº¦å¤ªæ…¢ï¼ˆ< 5 tokens/sï¼‰

**è¯Šæ–­**:

```bash
# æ£€æŸ¥ CPU ä½¿ç”¨ç‡
htop

# æ£€æŸ¥æ¸©åº¦
vcgencmd measure_temp

# æ£€æŸ¥ CPU é¢‘ç‡
cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_cur_freq
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# æ–¹æ¡ˆ 1: å¯ç”¨æ€§èƒ½æ¨¡å¼
echo performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor

# æ–¹æ¡ˆ 2: é™ä½æ•£çƒ­é˜»ç¢
# - æ£€æŸ¥é£æ‰‡æ˜¯å¦å·¥ä½œ
# - æ¸…ç†ç°å°˜
# - æ”¹å–„é€šé£

# æ–¹æ¡ˆ 3: ä¼˜åŒ–è¿è¡Œå‚æ•°
./server -m model.gguf \
    -t 4 \                    # ä½¿ç”¨æ‰€æœ‰ CPU æ ¸å¿ƒ
    --batch-size 512 \        # å¢å¤§æ‰¹å¤„ç†
    --threads-batch 4 \       # æ‰¹å¤„ç†çº¿ç¨‹æ•°
    --mlock                   # é”å®šå†…å­˜

# æ–¹æ¡ˆ 4: ä½¿ç”¨æ›´å°çš„é‡åŒ–
# Q4_K_M -> Q2_K

# æ–¹æ¡ˆ 5: å‡å°ä¸Šä¸‹æ–‡
# -c 2048 -> -c 1024
```

### âŒ é—®é¢˜: CPU æ¸©åº¦è¿‡é«˜ï¼ˆ> 75Â°Cï¼‰

**ç—‡çŠ¶**:
```bash
vcgencmd measure_temp
# temp=80.0'C  # å±é™©ï¼
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# æ–¹æ¡ˆ 1: æ·»åŠ æ•£çƒ­
# - å®‰è£…ä¸»åŠ¨é£æ‰‡ï¼ˆå¿…é¡»ï¼‰
# - æ·»åŠ æ•£çƒ­ç‰‡
# - æ”¹å–„æœºç®±é€šé£

# æ–¹æ¡ˆ 2: é™ä½è´Ÿè½½
# å‡å°‘çº¿ç¨‹æ•°: -t 2
# é™ä½é¢‘ç‡ï¼ˆä¸æ¨èï¼‰

# æ–¹æ¡ˆ 3: å¯ç”¨èŠ‚æµä¿æŠ¤
# ç¼–è¾‘ /boot/config.txt
sudo nano /boot/config.txt
# æ·»åŠ :
# temp_soft_limit=70

# æ–¹æ¡ˆ 4: ç›‘æ§æ¸©åº¦
watch -n 1 'vcgencmd measure_temp && vcgencmd get_throttled'

# å¦‚æœçœ‹åˆ° throttled=0x50000
# è¯´æ˜å·²ç»é™é¢‘ï¼Œå¿…é¡»æ”¹å–„æ•£çƒ­ï¼
```

---

## 7. ç½‘ç»œé—®é¢˜

### âŒ é—®é¢˜: æ— æ³•é€šè¿‡å±€åŸŸç½‘è®¿é—®

**ç—‡çŠ¶**:
- localhost å¯ä»¥è®¿é—®
- ä½†å±€åŸŸç½‘å…¶ä»–è®¾å¤‡æ— æ³•è®¿é—®

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. ç¡®è®¤æœåŠ¡ç›‘å¬æ‰€æœ‰æ¥å£
# åœ¨å¯åŠ¨å‘½ä»¤ä¸­ä½¿ç”¨ --host 0.0.0.0
./server --host 0.0.0.0 --port 8080

# 2. æ£€æŸ¥é˜²ç«å¢™
sudo ufw status
sudo ufw allow 8080

# 3. æµ‹è¯•è¿é€šæ€§
# åœ¨æ ‘è“æ´¾ä¸Š:
netstat -tuln | grep 8080

# åœ¨å…¶ä»–è®¾å¤‡ä¸Š:
ping raspberrypi.local
telnet raspberrypi.local 8080

# 4. æŸ¥çœ‹æ ‘è“æ´¾ IP
hostname -I
```

### âŒ é—®é¢˜: è¿œç¨‹è®¿é—®å»¶è¿Ÿé«˜

**ç—‡çŠ¶**:
- å“åº”æ—¶é—´ > 5 ç§’
- é¢‘ç¹è¶…æ—¶

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. ä½¿ç”¨æœ‰çº¿è¿æ¥è€Œé WiFi
# WiFi å»¶è¿Ÿé€šå¸¸ 5-20ms
# æœ‰çº¿å»¶è¿Ÿé€šå¸¸ 1-3ms

# 2. æ£€æŸ¥ç½‘ç»œè´¨é‡
ping raspberrypi.local
# ç†æƒ³æƒ…å†µ: < 10ms

# 3. ä½¿ç”¨ VPN (Tailscale)
curl -fsSL https://tailscale.com/install.sh | sh
sudo tailscale up

# 4. ä¼˜åŒ– HTTP è¿æ¥
# ä½¿ç”¨ HTTP/2 æˆ– WebSocket
```

---

## 8. ç³»ç»Ÿé—®é¢˜

### âŒ é—®é¢˜: SD å¡å†™å…¥é€Ÿåº¦æ…¢

**ç—‡çŠ¶**:
- ç³»ç»Ÿå“åº”æ…¢
- æ—¥å¿—æ˜¾ç¤º I/O é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. æµ‹è¯• SD å¡é€Ÿåº¦
sudo hdparm -t /dev/mmcblk0
# åº”è¯¥ > 20 MB/s

# 2. ä½¿ç”¨æ›´å¿«çš„ SD å¡
# æ¨è: SanDisk Extreme (A2, UHS-I)

# 3. è¿ç§»åˆ° NVMe SSD
# è´­ä¹° NVMe é€‚é…å™¨ + SSD
# ä½¿ç”¨ Raspberry Pi Imager çƒ§å½•åˆ° SSD

# 4. å‡å°‘æ—¥å¿—å†™å…¥
# ç¼–è¾‘ systemd æœåŠ¡
StandardOutput=null
StandardError=null
```

### âŒ é—®é¢˜: ç³»ç»Ÿä¸ç¨³å®š/éšæœºé‡å¯

**è¯Šæ–­**:

```bash
# æ£€æŸ¥ç”µæº
vcgencmd get_throttled
# å¦‚æœè¿”å›é 0ï¼Œè¯´æ˜ç”µæºä¸è¶³

# æ£€æŸ¥ç³»ç»Ÿæ—¥å¿—
dmesg | tail -50
sudo journalctl -p 3 -xb  # æŸ¥çœ‹é”™è¯¯æ—¥å¿—
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# æ–¹æ¡ˆ 1: ä½¿ç”¨å®˜æ–¹ç”µæºï¼ˆ27Wï¼‰
# æˆ–è‡³å°‘ 3A çš„ 5V ç”µæº

# æ–¹æ¡ˆ 2: ç¦ç”¨ USB è®¾å¤‡çœç”µæ¨¡å¼
# ç¼–è¾‘ /boot/config.txt
sudo nano /boot/config.txt
# æ·»åŠ :
# usb_max_current_enable=1

# æ–¹æ¡ˆ 3: é™ä½è¶…é¢‘ï¼ˆå¦‚æœæœ‰ï¼‰
# ç§»é™¤ config.txt ä¸­çš„è¶…é¢‘è®¾ç½®

# æ–¹æ¡ˆ 4: æ£€æŸ¥å†…å­˜
# è¿è¡Œå†…å­˜æµ‹è¯•
sudo apt install memtester
sudo memtester 1G 1
```

---

## ğŸ” è°ƒè¯•æŠ€å·§

### 1. è¯¦ç»†æ—¥å¿—æ¨¡å¼

```bash
# llama.cpp è¯¦ç»†æ—¥å¿—
./server -m model.gguf --verbose --log-file server.log

# systemd è¯¦ç»†æ—¥å¿—
sudo journalctl -u llama-server -f --since "5 minutes ago"

# ç³»ç»Ÿçº§æ—¥å¿—
dmesg -T | tail -50
```

### 2. æ€§èƒ½åˆ†æ

```bash
# CPU æ€§èƒ½åˆ†æ
top -H -p $(pgrep server)

# å†…å­˜åˆ†æ
sudo smem -t -k

# I/O åˆ†æ
sudo iotop -o
```

### 3. ç½‘ç»œè°ƒè¯•

```bash
# æŠ“åŒ…åˆ†æ
sudo tcpdump -i any port 8080 -w capture.pcap

# HTTP è¯·æ±‚æµ‹è¯•
curl -v http://localhost:8080/health

# å»¶è¿Ÿæµ‹è¯•
time curl http://localhost:8080/health
```

---

## ğŸ“ è·å–å¸®åŠ©

å¦‚æœä»¥ä¸Šæ–¹æ¡ˆéƒ½æ— æ³•è§£å†³é—®é¢˜ï¼š

1. **æ”¶é›†ä¿¡æ¯**:
```bash
# ç³»ç»Ÿä¿¡æ¯
uname -a
cat /etc/os-release
vcgencmd version

# ç¡¬ä»¶ä¿¡æ¯
cat /proc/cpuinfo | grep Model
free -h
df -h

# è½¯ä»¶ç‰ˆæœ¬
cd ~/llama.cpp && git log -1
./main --version
```

2. **åˆ›å»º Issue**:
   - æä¾›å®Œæ•´çš„é”™è¯¯ä¿¡æ¯
   - é™„ä¸Šç³»ç»Ÿä¿¡æ¯
   - è¯´æ˜å¤ç°æ­¥éª¤

3. **ç¤¾åŒºæ”¯æŒ**:
   - llama.cpp Discussions
   - Raspberry Pi Forums
   - Qwen GitHub Issues

---

## âœ… é¢„é˜²æªæ–½

ä¸ºäº†é¿å…é—®é¢˜ï¼š

1. âœ… ä½¿ç”¨å®˜æ–¹ç”µæºå’Œé…ä»¶
2. âœ… å®šæœŸæ›´æ–°ç³»ç»Ÿ: `sudo apt update && sudo apt upgrade`
3. âœ… ä¿æŒè‰¯å¥½æ•£çƒ­
4. âœ… å¤‡ä»½é‡è¦æ•°æ®
5. âœ… ä½¿ç”¨ UPS é˜²æ­¢çªç„¶æ–­ç”µ
6. âœ… ç›‘æ§ç³»ç»Ÿå¥åº·çŠ¶æ€

---

**é—®é¢˜ä»æœªè§£å†³ï¼Ÿæ¬¢è¿æäº¤ Issue æˆ–åœ¨ Discussions ä¸­è®¨è®ºï¼**